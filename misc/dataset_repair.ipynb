{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "from baal import ModelWrapper\n",
    "from active_fairness import utils\n",
    "from active_fairness.metrics import FairnessMetric\n",
    "from active_fairness.utils import get_datasets\n",
    "\n",
    "'''\n",
    "REPAIR resampling of datasets minimizing representation bias\n",
    "Returns a weight in [0, 1] for each example,\n",
    "\n",
    "Code from: https://github.com/JerryYLi/Dataset-REPAIR\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as skm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def repair(loader, attribute, feat_dim, epochs, lr, lr_w):\n",
    "    # class counts\n",
    "    labels = torch.tensor([data[1]['target'] for data in loader.dataset]).long().cuda()\n",
    "    n_cls = int(labels.max()) + 1\n",
    "    cls_idx = torch.stack([labels == c for c in range(n_cls)]).float().cuda()\n",
    "\n",
    "    # create models\n",
    "    model = nn.Linear(feat_dim, n_cls).cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    weight_param = nn.Parameter(torch.zeros(len(loader.dataset)).cuda())\n",
    "    optimizer_w = optim.SGD([weight_param], lr=lr_w)\n",
    "\n",
    "    # training\n",
    "    with tqdm(range(1, epochs + 1)) as pbar:\n",
    "        for _ in pbar:\n",
    "            losses = []\n",
    "            corrects = 0\n",
    "            for x, target, idx in loader:\n",
    "                y = y['target'].cuda()\n",
    "                sensible = y[attribute].cuda()\n",
    "\n",
    "                # class probabilities\n",
    "                w = torch.sigmoid(weight_param)\n",
    "                z = w[idx] / w.mean()\n",
    "                cls_w = cls_idx @ w\n",
    "                q = cls_w / cls_w.sum()\n",
    "\n",
    "                # linear classifier\n",
    "                out = model(sensible)\n",
    "                loss_vec = F.cross_entropy(out, y, reduction='none')\n",
    "                loss = (loss_vec * z).mean()\n",
    "                losses.append(loss.item())\n",
    "                corrects += out.max(1)[1].eq(y).sum().item()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                # class weights\n",
    "                optimizer_w.zero_grad()\n",
    "                entropy = -(q[y].log() * z).mean()\n",
    "                loss_w = 1 - loss / entropy\n",
    "                loss_w.backward()\n",
    "                optimizer_w.step()\n",
    "\n",
    "            loss = sum(losses) / len(losses)\n",
    "            acc = 100 * corrects / len(loader.dataset)\n",
    "            pbar.set_postfix(loss='%.3f' % loss, acc='%.2f%%' % acc)\n",
    "\n",
    "    # class probabilities & bias\n",
    "    with torch.no_grad():\n",
    "        w = torch.sigmoid(weight_param)\n",
    "        cls_w = cls_idx @ w\n",
    "        q = cls_w / cls_w.sum()\n",
    "        rnd_loss = -(q * q.log()).sum().item()\n",
    "        bias = 1 - loss / rnd_loss\n",
    "\n",
    "    print('Accuracy = {:.2f}%, Loss = {:.3f}, Rnd Loss = {:.3f}, Bias = {:.3f}'.format(acc, loss, rnd_loss, bias))\n",
    "    return w, q, cls_idx, cls_w, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,  DataLoader, Subset\n",
    "\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (*self.dataset[idx], idx)\n",
    "\n",
    "def get_keep_idx(w, cls_idx, threshold = 0.5, keep_ratio=0.5, mode='threshold'):\n",
    "    # strategy 1: fixed threshold\n",
    "    if mode == 'threshold':\n",
    "        keep_idx = (w > threshold).nonzero().cpu().squeeze()\n",
    "\n",
    "    # strategy 2: top k% examples\n",
    "    elif mode == 'rank':\n",
    "        keep_examples = round(keep_ratio * len(w))\n",
    "        keep_idx = w.sort(descending=True)[1][:keep_examples].cpu()\n",
    "\n",
    "    # strategy 3: top k% examples each class\n",
    "    elif mode == 'cls_rank':\n",
    "        keep_idx_list = []\n",
    "        for c in range(10):\n",
    "            c_idx = cls_idx[c].nonzero().squeeze()\n",
    "            keep_examples = round(keep_ratio * len(c_idx))\n",
    "            sort_idx = w[c_idx].sort(descending=True)[1]\n",
    "            keep_idx_list.append(c_idx[sort_idx][:keep_examples])\n",
    "        keep_idx = torch.cat(keep_idx_list).cpu()\n",
    "\n",
    "    # strategy 4: sampling according to weights\n",
    "    elif mode == 'sample':\n",
    "        keep_idx = torch.bernoulli(w).nonzero().cpu().squeeze()\n",
    "\n",
    "    # strategy 5: random uniform sampling\n",
    "    elif mode == 'uniform':\n",
    "        keep_examples = round(keep_ratio * len(w))\n",
    "        keep_idx = torch.randperm(len(w))[:keep_examples]\n",
    "\n",
    "    return keep_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyCrit(nn.Module):\n",
    "    def __init__(self, crit):\n",
    "        super().__init__()\n",
    "        self.crit = crit\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.crit(input, target['target'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attribute = 'color'\n",
    "dataset_path = '/datasets/fairface_like_dataset_50000.pkl'\n",
    "active_set, val_set, test_set = get_datasets(dataset_path, 10, attribute, 'char')\n",
    "train_dataset = active_set._dataset\n",
    "num_classes = len(test_set._all_target)\n",
    "num_group = len(test_set._all_attribute)\n",
    "\n",
    "criterion = MyCrit(nn.CrossEntropyLoss())\n",
    "model = utils.vgg16(pretrained=True, num_classes=num_classes)\n",
    "\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,\n",
    "                      weight_decay=5e-4)\n",
    "model = ModelWrapper(model, criterion)\n",
    "initial_weights = deepcopy(model.state_dict())\n",
    "\n",
    "model.add_metric('fair_recall',\n",
    "                     lambda: FairnessMetric(skm.recall_score, 'recall', average='micro',\n",
    "                                            attribute=attribute))\n",
    "model.add_metric('fair_accuracy',\n",
    "                 lambda: FairnessMetric(skm.accuracy_score, 'accuracy',\n",
    "                                        attribute=attribute))\n",
    "model.add_metric('fair_precision',\n",
    "                 lambda: FairnessMetric(skm.precision_score, 'precision', average='micro',\n",
    "                                        attribute=attribute))\n",
    "model.add_metric('fair_f1',\n",
    "                 lambda: FairnessMetric(skm.f1_score, 'f1', average='micro',\n",
    "                                        attribute=attribute))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Raw dataset\n",
    "\n",
    "model.load_state_dict(initial_weights)\n",
    "model.train_on_dataset(train_dataset, optimizer, 64, epoch=10, use_cuda=True, workers=12)\n",
    "\n",
    "# Validation!\n",
    "model.test_on_dataset(test_set, batch_size=32, use_cuda=True, workers=6, average_predictions=1)\n",
    "fair_logs = {}\n",
    "for met in ['fair_recall', 'fair_accuracy', 'fair_precision', 'fair_f1']:\n",
    "    fair_test = model.metrics[f'test_{met}'].value\n",
    "    fair_test = {'test_' + k: v for k, v in fair_test.items()}\n",
    "    fair_train = model.metrics[f'train_{met}'].value\n",
    "    fair_train = {'train_' + k: v for k, v in fair_train.items()}\n",
    "    fair_logs.update(fair_test)\n",
    "    fair_logs.update(fair_train)\n",
    "\n",
    "metrics = model.metrics\n",
    "# Send logs\n",
    "train_loss = metrics['train_loss'].value\n",
    "val_loss = metrics['test_loss'].value\n",
    "fair_logs.update({\"test_loss\": val_loss, \"train_loss\": train_loss})\n",
    "\n",
    "pprint(fair_logs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resampling!\n",
    "\n",
    "repair_dataset = IndexedDataset(train_dataset)\n",
    "train_loader = DataLoader(repair_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "w, q, cls_idx, cls_w, bias = repair(train_loader, attribute, 1, epochs=200, lr=1e-3, lr_w=10)\n",
    "\n",
    "\n",
    "# perform resampling\n",
    "sampling = 'threshold' # One of ['threshold', 'rank', 'cls_rank', 'sample', 'uniform']\n",
    "print('Resampling strategy:', sampling)\n",
    "keep_idx = get_keep_idx(w, cls_idx, mode=sampling)\n",
    "keep_idx_train = keep_idx\n",
    "print('Keep examples: {}/{} ({:.2%})'.format(len(keep_idx), len(w), len(keep_idx) / len(w)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train with resampling\n",
    "resampled_train_set = Subset(train_dataset, keep_idx_train)\n",
    "model.load_state_dict(initial_weights)\n",
    "model.train_on_dataset(resampled_train_set, optimizer, 64,\n",
    "                       epoch=10, use_cuda=True, workers=12)\n",
    "\n",
    "model.test_on_dataset(test_set, batch_size=32, use_cuda=True, workers=6,\n",
    "                      average_predictions=1)\n",
    "fair_logs = {}\n",
    "for met in ['fair_recall', 'fair_accuracy', 'fair_precision', 'fair_f1']:\n",
    "    fair_test = model.metrics[f'test_{met}'].value\n",
    "    fair_test = {'test_' + k: v for k, v in fair_test.items()}\n",
    "    fair_train = model.metrics[f'train_{met}'].value\n",
    "    fair_train = {'train_' + k: v for k, v in fair_train.items()}\n",
    "    fair_logs.update(fair_test)\n",
    "    fair_logs.update(fair_train)\n",
    "\n",
    "metrics = model.metrics\n",
    "# Send logs\n",
    "train_loss = metrics['train_loss'].value\n",
    "val_loss = metrics['test_loss'].value\n",
    "fair_logs.update({\"test_loss\": val_loss, \"train_loss\": train_loss})\n",
    "\n",
    "pprint(fair_logs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}